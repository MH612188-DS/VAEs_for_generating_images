
# Variational Autoencoder (VAE) on MNIST

This project implements a **Variational Autoencoder (VAE)** using TensorFlow and Keras to learn a 2D latent representation of the MNIST handwritten digits dataset. The model is trained to reconstruct input images while learning a meaningful latent space for generative sampling.

---

## ğŸ” Overview

- **Dataset**: MNIST (handwritten digits, 28x28 grayscale images)
- **Latent Dimension**: 2 (for visualization)
- **Architecture**:
  - Convolutional Encoder
  - Latent Sampling with Reparameterization Trick
  - Convolutional Decoder (using Conv2DTranspose)
- **Loss Function**:
  - Binary Cross-Entropy (Reconstruction Loss)
  - KL Divergence (Latent Regularization)

---

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ main.py                # Main script for training and evaluation
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ vae.keras          # Saved VAE model
â”‚   â”œâ”€â”€ encoder.keras      # Saved encoder
â”‚   â””â”€â”€ decoder.keras      # Saved decoder
â”œâ”€â”€ checkpoint.keras       # Best model checkpoint
â”œâ”€â”€ logs/                  # TensorBoard logs
â”œâ”€â”€ README.md              # Project documentation


âœ… Requirements
Python 3.7+

TensorFlow 2.x

NumPy

Matplotlib

SciPy

Install dependencies:

bash
Copy
Edit
pip install tensorflow numpy matplotlib scipy
ğŸš€ How to Run
Train the VAE:

bash
Copy
Edit
python main.py
Outputs:

Training logs and checkpoints

Latent space visualizations

Generated samples from the latent space

ğŸ§  Key Concepts
Variational Autoencoder (VAE)
A VAE learns to:

Compress input images into a latent space (z_mean, z_log_var)

Sample from that space using the reparameterization trick

Reconstruct the original image using a decoder

Loss function:

total_loss = reconstruction_loss + KL_divergence

Sampling Layer
Implements the reparameterization trick:

python
Copy
Edit
z = z_mean + exp(0.5 * z_log_var) * Îµ
Where Îµ ~ N(0, 1).

ğŸ“Š Visualization
The script generates:

Latent space plots

Sampled points in latent space with decoded images

Reconstruction comparisons (original vs. generated)

ğŸ’¾ Model Saving
After training:

vae.keras: Full VAE model

encoder.keras / decoder.keras: Components saved separately for reuse

ğŸ“ˆ TensorBoard
To visualize training:

bash
Copy
Edit
tensorboard --logdir=./logs
ğŸ“Œ Notes
Images are resized to 32x32 with padding for compatibility with conv layers.

The latent space is 2D to enable visualization of the data manifold.

ğŸ§ª Future Improvements
Extend to higher-dimensional latent space

Add conditional VAE (cVAE) with label inputs

Apply to more complex datasets (e.g., Fashion MNIST, CIFAR-10)

ğŸ“§ Contact
For questions or contributions, feel free to open an issue or contact the author.
